#
# APTrust Preservation Services config file
#

# *** NOTE ***
#
# The preservation services code can only load this file if you set
# the following two variables in your environment BEFORE trying to
# run the services.
#
# APT_CONFIG_DIR should be the absolute path to the directory containing
# the config file.
#
# APT_SERVICES_CONFIG should be the configuration you want to load.
# Typically, this will be one of "dev", "test", "demo", or "production".
#
# Preservation services code will then try to load the config at path
# $APT_CONFIG_DIR/.env.$APT_SERVICES_CONFIG

# BASE_WORKING_DIR is the directory under which preservation services
# may create new folders and files. For test and dev, this should be
# ~/tmp. For demo and production, probably /mnt/lvm/apt or something
# similar.
BASE_WORKING_DIR="~/tmp"

# Preservation buckets. Be sure to set these right for each environment.
# For testing, we're using a local Minio server, so we can call these
# whatever we want.
BUCKET_STANDARD_OR="preservation-or"
BUCKET_STANDARD_VA="preservation-va"
BUCKET_GLACIER_OH="glacier-oh"
BUCKET_GLACIER_OR="glacier-or"
BUCKET_GLACIER_VA="glacier-va"
BUCKET_GLACIER_DEEP_OH="glacier-deep-oh"
BUCKET_GLACIER_DEEP_OR="glacier-deep-or"
BUCKET_GLACIER_DEEP_VA="glacier-deep-va"
BUCKET_WASABI_OR="wasabi-or"
BUCKET_WASABI_VA="wasabi-va"

# INGEST_TEMP_DIR is a directory in which preservation services can
# keep temporary files during the ingest process.
INGEST_TEMP_DIR="~/tmp/pres-serv/ingest"

# Each of the INGEST_WORKERS settings below describes the number of
# go routines to run within each ingest worker. An ingest worker is a
# single executable that can run multiple concurrent go routines to do
# its work. Keep in mind that these go routines communicate with Redis,
# Pharos, and multiple S3 servers. Having multiple go routines means
# having multiple concurrent connections open to these services. While
# it's likely OK to have several concurrent S3 connections, it's probably
# not a good idea to have multiple concurrent connections to Pharos in
# a worker that sends a lot writes to Pharos. That's a recipe for a DDOS
# attack against ourselves. See the notes below for each setting.

# INGEST_PRE_FETCH_WORKERS describes the number of concurrent go routines
# to run inside the IngestPreFetchWorker. This worker is primarily engaged
# in downloading data from S3 receiving buckets, so it's OK to set this
# in the 2-4 range. This worker also issues a lot of GET and POST requests
# to Redis, so beware of setting it too high.
INGEST_PRE_FETCH_WORKERS=1

# INGEST_VALIDATION_WORKERS describes the number of concurrent go routines
# to run inside the IngestValidationWorker. This worker does a lot of
# Redis reads and writes, and very little other I/O of any kind.
# The validator is mainly just cross-checking Redis records against
# each other and against a BagIt profile. Setting this to 1-2 is probably
# sufficient in production.
INGEST_VALIDATION_WORKERS=1

# INGEST_REINGEST_CHECK_WORKERS describes the number of concurrent go routines
# to run inside the ReingestCheckWorker. This worker makes a lot of read/write
# calls to Redis, and potentially a lot of read-only calls to Pharos.
# Setting this to 1-2 is probably sufficient in production.
INGEST_REINGEST_CHECK_WORKERS=1

# INGEST_STAGING_WORKERS describes the number of concurrent go routines
# to run inside the IngestStagingWorker. This worker does a lot of reading
# from S3 receiving buckets and lots of writes to the S3 staging bucket.
# Probably best to set this in the 2-4 range in production, though note
# that setting it too high makes the go routines compete with eachother
# for bandwidth.
INGEST_STAGING_WORKERS=1

# INGEST_FORMAT_IDENFITICATION_WORKERS describes the number of concurrent
# go routines to run inside the IngestFormatIdentificationWorker. This worker
# reads approximately the first 128k bytes from each file in the staging
# bucket and passes them into FIDO, an external process, for identification.
# The constant spawning of external FIDO processes may be a problem if you
# set this too high. 2 is probably sufficient.
INGEST_FORMAT_IDENTIFICATION_WORKERS=1

# INGEST_STORAGE_WORKERS describes the number of concurrent
# go routines to run inside the IngestStorageWorker. This worker copies
# files from S3 staging to preservation and replication buckets. This
# may incur very little network I/O when copying to AWS preservation
# and replication, because it uses server-to-server S3 copies. Network
# I/O can be very high when copying to Wasabi and other non-AWS buckets
# because each copy involves streaming the file through the local server
# and then onto into target bucket. Start by setting this two 2 in
# production and go from there.
INGEST_STORAGE_WORKERS=1

# INGEST_STORAGE_VALIDATION_WORKERS describes the number of concurrent
# go routines to run inside the IngestStorageValidationWorker. This worker
# checks to see that each file copied to preservation and replication buckets
# is actually present and complete. It sends HEAD/Stat requests only, making
# a potentially large number of network requests with a small amound of data
# in each request. A setting of 2 is probably sufficent in production.
INGEST_STORAGE_VALIDATION_WORKERS=1

# INGEST_RECORD_WORKERS describes the number of concurrent
# go routines to run inside the IngestRecordWorker, which records
# ingest data in Pharos. Start by setting this to 2 in production,
# and be careful not to DDOS Pharos when scaling horizontally.
INGEST_RECORD_WORKERS=1

# INGEST_CLEANUP_WORKERS describes the number of concurrent
# go routines to run inside the IngestCleanupWorker, which deletes
# temporary ingest data from Redis, deletes the temporary files in the
# staging bucket, and removes the original tar file from the depositor's
# receiving bucket. A setting of 1-2 is probably sufficient in production.
INGEST_CLEANUP_WORKERS=1


# LOG_DIR is where preservation services writes its log files.
LOG_DIR="~/tmp/logs"

# LOG_LEVEL should be one of: CRITICAL, ERROR, WARNING, NOTICE, INFO
# OR DEBUG. For dev and test, it's usually DEBUG. For demo and prod,
# it should usually be INFO.
LOG_LEVEL=DEBUG

# MAX_DAYS_SINCE_LAST_FIXITY is the maximum number of days allowed
# between fixity checks. Per agreement with depositors, this is 90.
# In dev and test, we occasionally set it lower to force fixity checks
# to run.
MAX_DAYS_SINCE_LAST_FIXITY=90

# MAX_FILE_SIZE is the maximum file the system can handle. Since we're
# working with S3, this is 5TB, or 5497558138880. File size will be lower
# on the demo server, probably more like 5GB, or 5368709120
MAX_FILE_SIZE=5497558138880

# NSQ_LOOKUPD is the host name and port of the NSQ lookup daemon.
# By default, it runs on port 4161. Format should be "host:port"
NSQ_LOOKUPD="localhost:4161"

# NSQ_URL is the URL of the NSQ server. It typically runs on port 4151.
# Format should be "http(s)://host:port"
NSQ_URL="http://localhost:4151"

# PHAROS_API_KEY is the API key or token used to make Pharos API calls.
# For test, this key is hard-coded into the Pharos fixtures at
# test/fixtures/user.yml. The Docker container created by
# `make integration` automatically loads these fixtures on startup.
PHAROS_API_KEY="c3958c7b09e40af1d065020484dafa9b2a35cea0"

# PHAROS_API_USER is the email address of the user making Pharos API calls.
# For test, this user is hard-coded into the Pharos test fixtures,
# like the API key above.
PHAROS_API_USER="system@aptrust.org"

# PHAROS_API_VERSION is the current Pharos API version, which should be
# "v2"
PHAROS_API_VERSION="v2"

# PHAROS_URL is the URL of the Pharos server.
PHAROS_URL="http://localhost:9292"

# REDIS_DEFAULT_DB is the number of the Redis DB in which preservation
# services keeps its data. This should be 0 in most cases.
REDIS_DEFAULT_DB= 0

# REDIS_PASSWORD is the password requried to connect to the Redis
# server. In dev and test, this should be an empty string.
REDIS_PASSWORD=""

# REDIS_RETRIES is the number of times we should try to get a record
# from Redis. This is helpful in testing, as our test code often requests
# recently-inserted data before Redis is able to return it.
REDIS_RETRIES=3

# REDIS_RETRY_MS is the number of milliseconds between retries when
# we retry Redis requests.
REDIS_RETRY_MS=250ms

# REDIS_URL is the URL of the Redis server in the format "host:port".
# The default port is 6379. For dev and test, this should be localhost:6379.
REDIS_URL="localhost:6379"

# REDIS_USER is the user name required to connect to Redis. For dev and
# test, this should be an empty string.
REDIS_USER= ""

# RESTORE_DIR is the directory in which preservation services should build
# the bags it's restoring.
RESTORE_DIR="~/tmp/pres-serv/restore"

# SCRIPT_DIR is the path the script directory, which contains
# identify_format.sh and other scripts. In dev and test, this should be
# PROJECT_ROOT/scripts. In staging, demo, and production, it should
# contain an absolute path.
SCRIPT_DIR="PROJECT_ROOT/scripts"

# STAGING_BUCKET is the name of the bucket into which ingest workers copy
# files for staging, before they are fully ingested.
STAGING_BUCKET="staging"

# STAGING_UPLOAD_RETRIES is the number of times an ingest worker will
# try to upload a file to the staging bucket.
STAGING_UPLOAD_RETRIES=3

# STAGING_UPLOAD_RETRY_MS is the number of milliseconds to wait before
# retrying an upload to the S3 staging bucket.
STAGING_UPLOAD_RETRY_MS=250ms

# VOLUME_SERVICE_URL is the URL for the local volume server. This will
# always be on localhost, typically http://localhost:8898
VOLUME_SERVICE_URL="http://localhost:8898"

# Connection info for local S3 service. This is a minio server that
# runs in dev/test, but not demo/production.
# For localhost testing, use 'localhost' instead of '127.0.0.1' because
# Minio signed URLs use hostname, not IP.
S3_LOCAL_HOST="localhost:9899"
S3_LOCAL_KEY="minioadmin"
S3_LOCAL_SECRET="minioadmin"

# AWS S3 connection info. In dev/test, point back to the local S3
# provider, so we can't overwrite anything in demo/prod.
# For localhost testing, use 'localhost' instead of '127.0.0.1' because
# Minio signed URLs use hostname, not IP.
S3_AWS_HOST="localhost:9899"
S3_AWS_KEY="minioadmin"
S3_AWS_SECRET="minioadmin"

# Wasabi S3 connection info.In dev/test, point back to the local S3
# provider, so we can't overwrite anything in demo/prod.
# For localhost testing, use 'localhost' instead of '127.0.0.1' because
# Minio signed URLs use hostname, not IP.
S3_WASABI_HOST="localhost:9899"
S3_WASABI_KEY="minioadmin"
S3_WASABI_SECRET="minioadmin"
